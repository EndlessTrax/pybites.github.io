
<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="google-site-verification" content="lyiNqmFUtae2FGps4eCalBloZekygEIfjiV8tSPrjMY" />
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="https://pybit.es/theme/stylesheet/style.min.css">
  <link rel="stylesheet" type="text/css" href="https://pybit.es/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="https://pybit.es/theme/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css">
  <link rel="stylesheet" type="text/css" href="https://pybit.es/theme/stylesheet/ribbons.css">
  <link rel="stylesheet" type="text/css" href="https://pybit.es/theme/stylesheet/custom.css">

    <link href="https://pybit.es/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="PyBites Atom">

    <link href="https://pybit.es/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="PyBites RSS">

    <link rel="shortcut icon" href="https://pybit.es/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://pybit.es/favicon.ico" type="image/x-icon">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


<meta name="author" content="Cedric Sambre" />
<meta name="description" content="After going through the web scraping learning paths, I decided to get my hands dirty and apply my freshly gathered knowledge on a real life project. I explain some difficulties you might encounter while scraping and I also show some libraries that can help you visualizing data you have obtained." />
<meta name="keywords" content="Scraping, BeautifulSoup, NLP, SpaCy, WordCloud, python3.7, webscraping, data, cookiewall, error handling, ajax">
<meta property="og:site_name" content="PyBites"/>
<meta property="og:title" content="From Webscraper to Wordcloud"/>
<meta property="og:description" content="After going through the web scraping learning paths, I decided to get my hands dirty and apply my freshly gathered knowledge on a real life project. I explain some difficulties you might encounter while scraping and I also show some libraries that can help you visualizing data you have obtained."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://pybit.es/guest-webscraper-to-wordcloud.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-11-27 12:01:00+01:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://pybit.es/author/cedric-sambre.html">
<meta property="article:section" content="Learning"/>
<meta property="article:tag" content="Scraping"/>
<meta property="article:tag" content="BeautifulSoup"/>
<meta property="article:tag" content="NLP"/>
<meta property="article:tag" content="SpaCy"/>
<meta property="article:tag" content="WordCloud"/>
<meta property="article:tag" content="python3.7"/>
<meta property="article:tag" content="webscraping"/>
<meta property="article:tag" content="data"/>
<meta property="article:tag" content="cookiewall"/>
<meta property="article:tag" content="error handling"/>
<meta property="article:tag" content="ajax"/>
<meta property="og:image" content="https://pybit.es/images/featured/pb-guest.png">

<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@pybites" />
<meta name="twitter:title" content="From Webscraper to Wordcloud" />
<meta name="twitter:description" content="After going through the web scraping learning paths, I decided to get my hands dirty and apply my freshly gathered knowledge on a real life project. I explain some difficulties you might encounter while scraping and I also show some libraries that can help you visualizing data you have obtained." />
<meta name="twitter:image" content="https://pybit.es/images/featured/pb-guest.png">

  <title>PyBites &ndash; From Webscraper to Wordcloud</title>


</head>
<body>


  <!-- change ribbon color based on topic -->
  <div class="ribbon right
      brown
  ">
    <a href="https://codechalleng.es/via/pybites" target="_blank">Click here to code!</a>
  </div>

  <!-- change aside color based on topic -->
    <aside class='brown'>
  
    <div>
      <a href="https://pybit.es">
          <img src="https://pybit.es/theme/img/guest.png" alt="PyBites" title="PyBites">
      </a>
      <h1><a href="https://pybit.es">PyBites</a></h1>

<h2 id="sitesubtitle">A Community that Masters Python through Code Challenges</h2>
      <nav>
        <ul class="list">
          <li><a href="/pages/articles.html">Articles</a></li>
          <li><a href="/pages/challenges.html">Blog Challenges</a></li>
          <li><a href="https://codechalleng.es/">Python Exercises</a></li>
          <li><a href="https://training.talkpython.fm/courses/explore_100days_web/100-days-of-web-in-python">#100DaysOfCode</a></li>
          <li><a href="/pages/community.html">Join our Slack</a></li>
          <li><a href="/pages/search.html">Search</a></li>
        </ul>
      </nav>

      <div id='mc-dark'>
<!-- Begin MailChimp Signup Form -->
<hr class="softDivider">
<div id="mc_embed_signup">
<form action="//pybit.us14.list-manage.com/subscribe/post?u=822043293f280259d4b8d2a3e&amp;id=ac7e2eb9ef" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    
<div class="mc-field-group">
  <p><a href='http://us14.campaign-archive1.com/home/?u=822043293f280259d4b8d2a3e&id=ac7e2eb9ef'>Join our community</a> and grab our <i>Become a Better Python Developer</i> cheat sheet. Learn Python. Receive bonus material. Challenge yourself! (<a href="https://pybit.es/pages/privacy-policy">Privacy Policy</a>)</p>
    <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_822043293f280259d4b8d2a3e_ac7e2eb9ef" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Join Us" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
<!--End mc_embed_signup-->                  </div>

      <hr class="softDivider">

      <div id="ninjaWidget">
        <a href="https://codechalleng.es/via/pybites" target="_blank"><img src="https://codechalleng.es/static/img/honors/ninja_widget.png" alt="start earning PyBites Ninja Belts"></a>
      </div>
        
      <ul class="social">
        <li><a href="https://pybit.es/feeds/all.rss.xml" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/rss.png' alt='Our RSS Feed'></a></li>
        <li><a href="https://twitter.com/pybites" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/twitter.png' alt='Follow us on Twitter'></a></li>
        <li><a href="https://github.com/pybites/" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/github.png' alt='Follow us on Github'></a></li>
        <li><a href="https://instagram.com/pybites" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/instagram.png' alt='Follow us on Instagram'></a></li>
        <li><a href="https://www.youtube.com/channel/UCBn-uKDGsRBfcB0lQeOB_gA" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/youtube.png' alt='Follow us on Youtube'></a></li>
        <li><a href="https://www.facebook.com/groups/pybites/" target="_blank"><img src='https://pybit.es/theme/img/socialmedia/facebook.png' alt='Follow us on Facebook'></a></li>
      </ul>

      <br>
      <script src="https://apis.google.com/js/platform.js"></script>

	
    </div>


  </aside>
  <main>


<article class="single">
  <header>
    <h1 id="guest-webscraper-to-wordcloud">From Webscraper to Wordcloud</h1>
    <p>
          Posted by <a href="https://pybit.es/author/cedric-sambre.html">Cedric Sambre</a> on Wed 27 November 2019 in <a href="https://pybit.es/category/learning.html">Learning</a>


        &#8226; 6 min read
    </p>
  </header>


  <div>
    <p>Living in Belgium, I decided to scrape the Belgian newspaper <a href="https://www.hln.be/">Het Laatste Nieuws</a>.
I wanted to know what kept people busy when reading the news, so I went for a collection of all comments on all articles in the news section.</p>
<p>You can find the full code <a href="https://github.com/xWhiteListed/trashpyle">here</a>.</p>
<h2>Index</h2>
<ul>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#the-little-scraper-that-could">The Little Scraper that could</a><ul>
<li><a href="#bypassing-the-cookiewall">Bypassing The Cookiewall</a></li>
<li><a href="#getting-the-articles">Getting the articles</a></li>
<li><a href="#the-comments-a-new-challenge">The Comments, A new challenge</a></li>
</ul>
</li>
<li><a href="#a-tiny-bit-of-ai-spacy">A tiny bit of AI: SpaCy</a></li>
<li><a href="#making-things-pretty-wordcloud">Making things pretty: WordCloud</a></li>
<li><a href="#future">Things for the future</a></li>
</ul>
<p><a name="requirements"></a></p>
<h2>Requirements</h2>
<ul>
<li><a href="https://pypi.org/project/requests/">Requests</a></li>
<li><a href="https://pypi.org/project/beautifulsoup4/">BeautifulSoup</a></li>
<li><a href="https://pypi.org/project/spacy/">SpaCy</a></li>
<li><a href="https://pypi.org/project/wordcloud/">WordCloud</a></li>
<li><a href="https://pypi.org/project/numpy">Numpy</a></li>
</ul>
<p><a name="the-little-scraper-that-could"></a></p>
<h2>The little Scraper that could</h2>
<p><a name="bypassing-the-cookiewall"></a></p>
<h3>Bypassing the cookiewall</h3>
<p>According to <a href="https://www.cookielaw.org">cookielaw.org</a> the cookielaw can be described as following:</p>
<blockquote>
<p>The Cookie Law is a piece of privacy legislation that requires websites to get consent from visitors to store or retrieve any information on a computer, smartphone or tablet.</p>
<p>It was designed to protect online privacy, by making consumers aware of how information about them is collected and used online, and give them a choice to allow it or not.</p>
</blockquote>
<p>This means that if we haven't visited the page before, we will be greeted with a message that will block our access, asking for permission to put the cookies on our computer.</p>
<p><img alt="The great Cookiewall of HLN" src="images/scraper-wordcloud/cookiewall.png"></p>
<p>To get past this 'cookiewall', the server needs to be presented with a cookie, so it knows we have given consent and it can track us without legal implications.</p>
<p>I also set my user agent to the same as the one on my computer, so there would be no differences in the source presented to me based on what browser I was using.</p>
<div class="highlight"><pre><span></span><span class="n">user_agent</span> <span class="o">=</span> <span class="s1">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36&#39;</span>
<span class="n">consent_cookie</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pws&#39;</span><span class="p">:</span> <span class="s1">&#39;functional|analytics|content_recommendation|targeted_advertising|social_media&#39;</span><span class="p">,</span> <span class="s1">&#39;pwv&#39;</span><span class="p">:</span> <span class="s1">&#39;1&#39;</span><span class="p">}</span>
<span class="o">...</span>
<span class="k">def</span> <span class="nf">get_pagedata</span><span class="p">():</span>
    <span class="n">reqdata</span> <span class="o">=</span> <span class="n">req_session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;https://www.hln.be/nieuws&quot;</span><span class="p">,</span> <span class="n">cookies</span><span class="o">=</span><span class="n">consent_cookie</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="n">user_agent</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">reqdata</span>
</pre></div>


<p>Et voila! No more cookiewalls, let the scraping begin!</p>
<p><a name="getting-the-articles"></a></p>
<h3>Getting the articles</h3>
<p>Now that I could get all the links, I had to go back to the HTML source of the page to figure out a good way to obtain the articles.
I ended up with a pretty conclusive piece of code for the time of writing, and also added a way to get the categories for the articles as labeled by HLN.</p>
<p>All these records were turned into <code>Article</code> namedtuples:</p>
<div class="highlight"><pre><span></span><span class="n">Article</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Article&#39;</span><span class="p">,</span> <span class="s1">&#39;hash headline url categories&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_all_articles</span><span class="p">(</span><span class="n">reqdata</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">reqdata</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
    <span class="n">article_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">html_article_list</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findChildren</span><span class="p">(</span><span class="s2">&quot;article&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">html_article</span> <span class="ow">in</span> <span class="n">html_article_list</span><span class="p">:</span>
        <span class="n">article_wrappers</span> <span class="o">=</span> <span class="n">html_article</span><span class="o">.</span><span class="n">findChildren</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">html_indiv_articles</span> <span class="o">=</span> <span class="n">article_wrappers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">findChildren</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;teaser-link--color&quot;</span><span class="p">})</span>
            <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">html_indiv_articles</span><span class="p">:</span>
                <span class="n">article_link</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
                <span class="n">categories</span> <span class="o">=</span> <span class="n">get_categories_from_article</span><span class="p">(</span><span class="n">article_link</span><span class="p">)</span>
                <span class="n">article_title</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">findChild</span><span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
                <span class="k">if</span> <span class="n">article_title</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">article_title</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">article_title</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                        <span class="nb">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">sha1</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha1</span><span class="p">()</span>
                <span class="n">sha1</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">article_title</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
                <span class="n">article_hash</span> <span class="o">=</span> <span class="n">sha1</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
                <span class="n">article_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">Article</span><span class="p">(</span><span class="nb">hash</span><span class="o">=</span><span class="n">article_hash</span><span class="p">,</span> <span class="n">headline</span><span class="o">=</span><span class="n">article_title</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">article_link</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="c1"># these are the divs from the most-read category, we should already have these.</span>
            <span class="k">continue</span>
</pre></div>


<p>I was pretty agressive on errorhandling by either <code>exit()</code>ing completely, or simply ignoring the exception and <code>continu</code>ing my loop, but that is because I feel scraping is a precise art and if data is something different than what you expect, you're expecting the wrong data!</p>
<p>Finally, I looped over the article list because I noticed that there were doubles (some articles might be on a 'featured' bar, and it was sometimes hard to distinguish between them)</p>
<div class="highlight"><pre><span></span>    <span class="n">clean_article_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="p">[</span><span class="n">clean_article_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">itm</span><span class="p">)</span> <span class="k">for</span> <span class="n">itm</span> <span class="ow">in</span> <span class="n">article_list</span> <span class="k">if</span> <span class="n">itm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">clean_article_list</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">clean_article_list</span>
</pre></div>


<p><a name="the-comments-a-new-challenge"></a></p>
<h3>The Comments, a new challenge</h3>
<p>Now that I had a list of all articles and the links to them, I wanted to get started by getting all the comments when I noticed my first scraping run had only gotten me 2 or 3 per article.
Knowing there were 100's of comments on some of the articles in my article dataset, I realized something was wrong.</p>
<p>Back at the drawing board, we found the problem. A little thing called Ajax.</p>
<p>Every article loaded a couple of comments, and a link that said 'Show more comments'. 
<img alt="Comments" src="images/scraper-wordcloud/recursive-comments.png"></p>
<p>When clicking this link, an Ajax call was made to get the next comments.
If there were more after that, a link was also included for the next ajax call.</p>
<p>The solution came with <em>regex</em>, as the Ajax links all were in a very specific pattern! </p>
<p>Still, the recursiveness in the puzzle was a bit challenging.</p>
<div class="highlight"><pre><span></span><span class="n">comment_regex</span> <span class="o">=</span> <span class="s2">&quot;href=</span><span class="se">\&quot;</span><span class="s2">(https\:\/\/www\.hln\.be\/ajax\/comments\/(.*?)\/start\/ts_\d*?)</span><span class="se">\&quot;</span><span class="s2">&gt;&quot;</span>
<span class="n">comment_rxobj</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">comment_regex</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_comments_from_page</span><span class="p">(</span><span class="n">reqdata</span><span class="p">,</span> <span class="n">article_hash</span><span class="p">):</span>
    <span class="n">comment_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">reqdata</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="n">comments_list_ul</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ul&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;comments__list&quot;</span><span class="p">})</span>
    <span class="k">if</span> <span class="n">comments_list_ul</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">comment_list</span>
    <span class="n">comments_indiv_li</span> <span class="o">=</span> <span class="n">comments_list_ul</span><span class="o">.</span><span class="n">findChildren</span><span class="p">(</span><span class="s2">&quot;li&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;comment&quot;</span><span class="p">})</span>

    <span class="k">for</span> <span class="n">comment</span> <span class="ow">in</span> <span class="n">comments_indiv_li</span><span class="p">:</span>
        <span class="n">comment_author</span> <span class="o">=</span> <span class="n">comment</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;h2&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;comment__author&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">text</span>
        <span class="n">comment_body</span> <span class="o">=</span> <span class="n">comment</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;comment__body&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">comment_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Comment</span><span class="p">(</span><span class="n">article_hash</span><span class="o">=</span><span class="n">article_hash</span><span class="p">,</span> <span class="n">commenter</span><span class="o">=</span><span class="n">comment_author</span><span class="p">,</span> <span class="n">comment_text</span><span class="o">=</span><span class="n">comment_body</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">comment_list</span>

<span class="k">def</span> <span class="nf">get_all_comments</span><span class="p">(</span><span class="n">article_main_link</span><span class="p">,</span> <span class="n">article_hash</span><span class="p">):</span>
    <span class="n">comment_href_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">comment_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">article_reqdata</span> <span class="o">=</span> <span class="n">req_session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">article_main_link</span><span class="p">,</span> <span class="n">cookies</span><span class="o">=</span><span class="n">consent_cookie</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="n">user_agent</span><span class="p">})</span>
    <span class="n">reqdata</span> <span class="o">=</span> <span class="n">article_reqdata</span>
    <span class="n">comment_list</span> <span class="o">+=</span> <span class="n">get_comments_from_page</span><span class="p">(</span><span class="n">reqdata</span><span class="o">=</span><span class="n">reqdata</span><span class="p">,</span> <span class="n">article_hash</span><span class="o">=</span><span class="n">article_hash</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">comment_rxobj</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">reqdata</span><span class="o">.</span><span class="n">text</span><span class="p">):</span>
        <span class="n">comment_href_group</span> <span class="o">=</span> <span class="n">comment_rxobj</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">reqdata</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="n">comment_href</span> <span class="o">=</span> <span class="n">comment_href_group</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">comment_href_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comment_href</span><span class="p">)</span>

        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">sleeptime</span><span class="p">)</span>
        <span class="n">reqdata</span> <span class="o">=</span> <span class="n">req_session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">comment_href</span><span class="p">,</span> <span class="n">cookies</span><span class="o">=</span><span class="n">consent_cookie</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="n">user_agent</span><span class="p">})</span>

        <span class="n">comment_list</span> <span class="o">+=</span> <span class="n">get_comments_from_page</span><span class="p">(</span><span class="n">reqdata</span><span class="o">=</span><span class="n">reqdata</span><span class="p">,</span> <span class="n">article_hash</span><span class="o">=</span><span class="n">article_hash</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">comment_list</span>
</pre></div>


<p>Because I didn't want to be sending too many requests in a short span, I also added some ratelimiting to not be too aggressive towards the hln server.</p>
<p><a name="a-tiny-bit-of-ai-spacy"></a></p>
<h2>A tiny bit of AI: SpaCy</h2>
<p>If we want to know what people are talking about, we have to be able to recognize the different parts of a sentence.
If we would simply look at all words, a lot of 'non-descriptive' words would probably show up.
It would still give a good image, but a lot of space would probably be taken by stop words or conjunctions (like 'and')</p>
<p>What we really care about is the subjects people are talking about, the Nouns of the lines they write. That's where SpaCy comes in!</p>
<p><a href="https://spacy.io">SpaCy</a> is an open source library for Natural Language Processing.
There are trained models for a set of languages that can be used for <a href="https://spacy.io/usage/linguistic-features">a lot of different things</a>.</p>
<p>This allowed us to create a dictionary of 'types' of words:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;nl_core_news_sm&#39;</span><span class="p">)</span>
<span class="o">...</span>
<span class="k">def</span> <span class="nf">get_wordtype_dict</span><span class="p">(</span><span class="n">raw_comment_list</span><span class="p">):</span>
    <span class="n">wordtype_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">comment</span> <span class="ow">in</span> <span class="n">raw_comment_list</span><span class="p">:</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">comment</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
            <span class="n">wordtype_dict</span><span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">wordtype_dict</span>
</pre></div>


<p>Outputting the first 5 words for each token:</p>
<div class="highlight"><pre><span></span>ADV:
    Eindelijk
    niet
    nu
    nog
    eens
    zo

PUNCT:
    !
    ...
    .
    .
    .
    .
PRON:
    Ik
    dat
    ik
    Ik
    Wat
    dat
VERB:
    ga
    kijken
    Kan
    wachten
    noem
    zie
NOUN:
    Hemels
    nieuws
    ziekte
    Pia
    leven
    toegewenst
</pre></div>


<p>The classification was not the most accurate but it was enough for what I wanted to do.</p>
<p>I plan on retraining the model with my new data in the future to hopefully get a more accurate model for Belgian comments with its dialects.</p>
<p><a name="making-things-pretty-wordcloud"></a></p>
<h2>Making things pretty: WordCloud</h2>
<p>Now that I had the data, all I had to do was find a way to visualize it.
<a href="https://github.com/amueller/word_cloud">Wordcloud</a> is a library designed to make... well, wordclouds!</p>
<p>The wordcloud library takes a blob of text, and takes turns them in to wordclouds with the size of the words reflecting the number of occurences.
After turning the lists of words in our worddict into strings, 2 lines of code were enough to produce a result:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_word_cloud</span><span class="p">(</span><span class="n">text_blob</span><span class="p">):</span>
    <span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">1600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">background_color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">text_blob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordcloud</span>
</pre></div>


<p>For our nouns, this gave us:</p>
<p><img alt="Wordcloud Result" src="images/scraper-wordcloud/wordcloud-NOUN.png"></p>
<p>You could also use a logo to generate the wordcloud by creating an <code>ImageColorGenerator()</code> and passing it to the wordcloud constructor:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_word_cloud_logo</span><span class="p">(</span><span class="n">text_blob</span><span class="p">):</span>
    <span class="n">rgb_hln_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">load_hln_logo</span><span class="p">())</span>
    <span class="n">wcig</span> <span class="o">=</span> <span class="n">ImageColorGenerator</span><span class="p">(</span><span class="n">rgb_hln_arr</span><span class="p">)</span>
    <span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">1600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">background_color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">rgb_hln_arr</span><span class="p">,</span> <span class="n">color_func</span><span class="o">=</span><span class="n">wcig</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">text_blob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wordcloud</span>
</pre></div>


<p>For ALL the words, this resulted in:</p>
<p><img alt="Wordcloud Logo Result" src="images/scraper-wordcloud/wordcloud-ALL.png"></p>
<p><a name="future"></a></p>
<h2>Things for the future</h2>
<p>There's room for a lot of improvement in this project, below are some things I <em>really</em> want to get done and you might see me write about in the future:</p>
<ul>
<li>
<p>Improve the spacy model for dutch/belgian POS Tagging.</p>
</li>
<li>
<p>This same project but with a more Object Oriented approach </p>
</li>
<li>
<p>Fix the encoding issues in the scraper</p>
</li>
<li>
<p>Sentiment Analysis</p>
</li>
<li>
<p>Merging word groups by combining POS Tagging and Dependency Parsing </p>
</li>
</ul>
<p>--</p>
<p>Thanks for reading, I hope you enjoyed it as much as I enjoyed writing it. 
If you have any remarks or questions, you can likely find me on the <a href="http://localhost:8000/pages/community.html">Pybites Slack Channel</a> as 'Jarvis'.</p>
<p>Keep calm and code in Python!</p>
<p>-- <a href="pages/guests.html#cedricsambre">Cedric</a></p>
  </div>

  <hr>
  <p><strong>See an error in this post? Please submit a pull request <a href='https://github.com/pybites/pybites.github.io-src' target='_blank'>on Github.</a></strong></p>

  <div class="tag-cloud">
    <p>
      <a href="https://pybit.es/tag/scraping.html">Scraping</a>
      <a href="https://pybit.es/tag/beautifulsoup.html">BeautifulSoup</a>
      <a href="https://pybit.es/tag/nlp.html">NLP</a>
      <a href="https://pybit.es/tag/spacy.html">SpaCy</a>
      <a href="https://pybit.es/tag/wordcloud.html">WordCloud</a>
      <a href="https://pybit.es/tag/python37.html">python3.7</a>
      <a href="https://pybit.es/tag/webscraping.html">webscraping</a>
      <a href="https://pybit.es/tag/data.html">data</a>
      <a href="https://pybit.es/tag/cookiewall.html">cookiewall</a>
      <a href="https://pybit.es/tag/error-handling.html">error handling</a>
      <a href="https://pybit.es/tag/ajax.html">ajax</a>
    </p>
  </div>

  <div class="center social-share">
    <p>    Like this article? Share it with your friends!
</p>
    <div class="addthis_native_toolbox"></div>
    <div class="addthis_sharing_toolbox"></div>
  </div>



<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'http-pybit-es';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
        Please enable JavaScript to view comments.

</noscript>
</article>

    <footer>
<p>&copy; pybites </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89294245-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

	<script>window.twttr = (function(d, s, id) {
	var js, fjs = d.getElementsByTagName(s)[0],
		t = window.twttr || {};
	if (d.getElementById(id)) return t;
	js = d.createElement(s);
	js.id = id;
	js.src = "https://platform.twitter.com/widgets.js";
	fjs.parentNode.insertBefore(js, fjs);
	t._e = [];
	t.ready = function(f) {
		t._e.push(f);
	};
	return t;
	}(document, "script", "twitter-wjs"));</script>

  <script async defer src="https://buttons.github.io/buttons.js"></script>
	
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5859c6a67eb6254d" async="async"></script>


<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " PyBites ",
  "url" : "https://pybit.es",
  "image": "https://pybit.es/theme/img/profile.png",
  "description": "A Community that Masters Python through Code Challenges"
}
</script>
</body>
</html>